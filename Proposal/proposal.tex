\documentclass[9pt]{article}
\usepackage[a4paper,total={6in,9in}]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{csquotes}
\usepackage[backend=biber,style=alphabetic,sorting=ynt]{biblatex}
\addbibresource{mybib.bib}
\usepackage{algorithm}

\title{\textbf{Our stories, their style \\ Data Vaders}}

\author{Soumye Singhal \\ 150728 \and Abhibhav Garg \\ 150010 \and Prakhar Agrawal \\150499 \and K Siddarth
\\150069}
\date{\today}

\begin{document}

\maketitle

\section*{Introduction}
% Tell something about RNN's and 
The aim of our project is to capture the artistic style of an author and then generate text in that same style. Formally,given a starting sentence and a target author (say JK Rowling), we use text generation methods to complete a paragraph in the style of that author. 
 
\section*{Related Work}
There has been an increasing amount of work done in applying RNN's to a wide variety of problems. There has also been some work done in style transfer in \cite*{2015arXiv150806576G} %cite%



\section*{Aim and Proposed Contributions}
We aim to accomplish this task of text generation by building a character-level language models using multi-layered RNNs/LSTM. What this model does is that given a large chunk of text, it learns to generate text like it character by character using the power of RNNs, which is exactly what we need. We will also experiment with various models of RNN's like LSTMs and GRU's and compare their performance. We also aim to use style transfer techniques using character RNN to capture the style of the author. The vanilla character RNN has various issues most prominent being it fails to capture long-term dependencies. We aim to mitigate those by incorporating an attention model into that like neural turing machines.
For the dataset, we will simply use the openly available version of the texts of the respective author from sources like 'Project Gutenberg'. 
\par



\section*{Timeline}
We present a timeline for our work as follows :


\begin{itemize}
    \item \textbf{Midsem evaluation} : We first aim to learn all the essentials of ANNs, RNN's and attention models to get started with and then implement a basic character RNN/LSTM in Tensorflow.  
    \item \textbf{EndSem evaluation} : After implementing the vanilla character RNN/LSTM we will  
\end{itemize}
\printbibliography

\end{document}

        
